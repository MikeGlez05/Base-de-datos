# -*- coding: utf-8 -*-
"""Practica_1_Gonzalez_Coria_Miguel_Angel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13UVZps4omQkNZavN77V4bP6veidTtRzS

**Practica 1**

Gonzalez Coria Miguel Angel
"""

import pandas as pd
import numpy as np

"""# Con los datos proporcionados realiza los siguientes puntos:

"""

df= pd.read_csv("spotify_practica.csv")
df.head()

"""# (a) Realiza el etiquetado de las variables de acuerdo a su tipo de variable"""

## Realiza el etiquetado de las variables de acuerdo a su tipo de variable ##
#Consideremos variables discretas, continuas, string

c_feats = ['acousticness', 'danceability', 'energy','explicit', 'explicit', 'instrumentalness',
           'key', 'liveness', 'loudness', 'popularity', 'popularity', 'speechiness', 'tempo', 'valance']
d_feats = ['duration_ms', 'mode','zip Code','genero']
t_feats = ['release_date']
s_feats = ['artists', 'id', 'name']

c_feats_new = ['c_' + x for x in c_feats]
d_feats_new = ['d_' + x for x in d_feats]
t_feats_new = ['t_' + x for x in t_feats]
s_feats_new = ['s_' + x for x in s_feats]

df.rename(columns = dict(zip(c_feats, c_feats_new)), inplace=True)
df.rename(columns = dict(zip(d_feats, d_feats_new)), inplace=True)
df.rename(columns = dict(zip(t_feats, t_feats_new)), inplace=True)
df.rename(columns = dict(zip(s_feats, s_feats_new)), inplace=True)

## Ya tenemos aqui nuesnuestras columnas con sus respectivas etiquetas.

df.columns

"""# (b) Imprime cuántos duplicados hay en la base de datos y elíminalos"""

df.duplicated().sum()

##Estos serán ahora los no duplicados

df.drop_duplicates(inplace = True)

df.reset_index(drop = True, inplace = True)

df = df.reset_index(drop=True)

##Ya no hay duplicados aqui
df.shape

"""# (c) Realiza la completitud de las variables"""

## Trabajemos con la completitud

comple = pd.DataFrame(df.isnull().sum())

comple.reset_index(drop = True)

comple = comple.rename(columns={'index':'columna', 0:'total'})

comple['Completitud'] = (1 - comple['total']/df.shape[0])*100

comple = comple.sort_values(by='Completitud', ascending = True) # Completitud de las variables
comple

"""# (d) Elimina las variables que tengan el 20% o más de valores ausentes"""

# Hay que ver cuanto es el 80%, ya que estos son los unicos se sobreviven

rango = len(df) * 0.8
rango

df= df.dropna(thresh = rango, axis = 1)

df.shape[1] ##Ya se borraron las que no cumplen el criterio del 20%. Quedando solo 18 columnas.

df.columns # Las nuevas columnas

"""# (e)¿Cuántos de los registros en la variable “zip Code” son valores no válidos?, es decir, contienen letras"""

zip_code_invalidos = df[df['d_zip Code'].astype(str).str.contains('[a-zA-Z]', na=False)]
#Este df solo contiene a los valores de zip Code que no son invalidos

invalidos = len(zip_code_invalidos) # CUantos valores son
invalidos

zip_code_invalidos['d_zip Code'].head(10)  # Como son mucho solo mostramos los primeros 10 para revisión

"""# (f) Elimina los registros que no tengas un “zip Code” válidos.

"""

df = df[~df['d_zip Code'].astype(str).str.contains('[a-zA-Z]', na=False)] # Guardamos en el df los valores validos de zip Code

df['d_zip Code'].unique() #Aqui se ve como el zip code ya esta limpio

"""# (g) ¿Cuántos de los registros en la variable “genero” son valores no validos?, es decir, contienen letras"""

genero_invalidos = df[df['d_genero'].astype(str).str.contains('[a-zA-ZА-Яа-я]', na=False)]

gen_invalidos = len(genero_invalidos)
gen_invalidos #Estos contienen letras

genero_invalidos['d_genero'].unique() #Ejemplo de no validos

"""# (h) Elimina los registros que no tengas un “genero” válido, es decir contenga letras en los valores"""

df = df[~df['d_genero'].astype(str).str.contains('[a-zA-ZА-Яа-я]', na=False)]

len(df)

df['d_genero'].unique() #Validos

"""# Haz una limpieza de la variable “name”, elimina caracteres especiales y todo debe estar en minúsculas"""

import unicodedata
import re

def clean_text(text, pattern="[^a-zA-Z0-9 ]"):

    cleaned_text = unicodedata.normalize('NFD', text).encode('ascii', 'ignore')
    cleaned_text = re.sub(pattern, " ", cleaned_text.decode("utf-8"), flags=re.UNICODE)
    cleaned_text = u' '.join(cleaned_text.lower().strip().split())
    return cleaned_text

#Creamos esta función que nos sirve para estandarizar las variables de texto

df["s_name"] = df["s_name"].map(lambda x:clean_text(x.lower()).replace("\n",""))

df['s_name'].unique()

"""# (j) De la variable “artista” selecciona solo al primer artista que aparezca en la lista además de eliminar caracteres especiales e imprime los primeros 5 artistas que aparecen en tu dataframe hasta este momento."""

#Toma el primer artista y elimina caracteres
df['s_artists'] = df['s_artists'].str.extract(r"\[?'([^']+)'\]?")
df['s_artists'] = df['s_artists'].str.replace(r'[^\w\s]', '', regex=True)


df['s_artists'].head()

"""#(k)Normaliza la variable “genero” de tal forma que obtengas solo 10 categorías"""

df['d_genero'].unique()# Estos son los valores que tenemos.

# Hay que hacer los datos sea de tipo string
df['d_genero'] = df['d_genero'].astype(str)

# Luego categorizar
def categorizar_genero(valor):
    if valor in ['1', '2', '3']:
        return '1-3'
    else:
        return valor

df['d_genero_categorizado'] = df['d_genero'].apply(categorizar_genero)

print(df['d_genero_categorizado'].value_counts().sort_index())

"""# (l) Añade las siguientes columnas a tu table base: zip, lat, lng, city, state_name utilizando la tabla zips_practica"""

df_new= pd.read_csv('zips_practica.csv') #Cargamos el nuevo df
df_new.head()

#Para que podamos usar una columna de base para añadir las otras, usamos el mismo nombre.
df.rename(columns = {'d_zip Code':'zip'}, inplace=True)

df['zip'] = df['zip'].astype(str)
df_new['zip'] = df_new['zip'].astype(str) #Las dos columnas son tipo str, asi evitamos errores al traspasar con merge

df = df.merge(df_new[['zip', 'lat', 'lng', 'city', 'state_name']], on= 'zip', how= 'left')
df.columns

"""# (m) Convierte las variables “lat” y “lng” en tipo flotante y valida que la información sea consistente"""

df['lat'] = pd.to_numeric(df['lat'], errors = 'coerce').clip(-90, 90)
df['lng'] = pd.to_numeric(df['lng'], errors = 'coerce').clip(-180, 180) ##Tipos flotante

df[['lat', 'lng']].value_counts()

"""Para validar los valores de lat y lng, se tiene que considerar lo siguiente:
lat: va de [-90 a 90]
lng: va de [-180 a 180]

# (n) De la variable “city” y “state” elimina los dígitos que se encuentran dentro de las cadenas de texto
"""

def clean_num(column):
    cleaned = column.apply(lambda x: re.sub(r'[^a-zA-Z\s\'-]', '', str(x)))
    cleaned = cleaned.apply(lambda x: re.sub(r'\s+', ' ', str(x)).strip())
    return cleaned

df['city'] = clean_num(df['city'])
df['state_name'] = clean_num(df['state_name']) ##Se limpian los valores numericos para city y statestate_name

df

"""# (o) Crea una nueva variable llamada “state” que este conformada por “city” y "state_name”"""

state = df[['city', 'state_name']]
state

"""# (p) Los valores de la nueva variable “state” modifícalos de cierta forma que todas sean minúsculas y sin acentos"""

state['city'] = state['city'].apply(clean_text)
state['state_name'] = state['state_name'].apply(clean_text)#Se uso la funcion de claclase clean_text

state = state[['city', 'state_name']]
state ##Ya estan limpios, sin acento y en minusculas.

"""# (q) Convierte los valores en la variable “release_date” a tipo datetime, además haz el conteo de las que no tienen la estructura necesaria para ser convertida en datetime y elimina ese registro"""

df['t_release_date'] = pd.to_datetime(df['t_release_date'], errors = 'coerce')
df['t_release_date'].isna().sum() ##Vemos cuales no se pudieron

df['t_release_date'].unique() # Al parecer todos se pudieron combertir a datetime asi que no hay que borrar

"""#2. De la tabla tratada obtén los siguientes datos:
#(a)Crea un DataFrame donde se muestre el conteo de registros por género
"""

# Contar registros por género
conteo_genero = df["d_genero_categorizado"].value_counts().reset_index()

conteo_genero.columns = ["Genero", "Conteo"]

conteo_genero ##Data creado

"""# (b)Genera una nueva variable que se llame “duration_minutos” que sea el valor de la variable “duration_ms” en minutos"""

df['duration_minutos']= df['d_duration_ms']/60000
df['duration_minutos']

"""# (c) ¿Cuáles son las 10 canciones más populares?"""

top_10 = df.nlargest(10, 'c_popularity')

top_10[['s_name', 's_artists', 'c_popularity']].reset_index()

"""# (d)¿Cuál es el promedio de duración en minutos y milisegundos?"""

promedio_min = df['duration_minutos'].mean()
promedio_ms = df['d_duration_ms'].mean()

print(f"Promedio de {promedio_ms:,.2f} milisegundos de duración")
print(f"Promedio de {promedio_min} minutos de duración")

df.columns

"""# (e)¿Cuál es el promedio y conteo de “energy” por “genero”? Crea un dataframe para responder esta pregunta"""

energy_descrip = df.groupby('d_genero')['c_energy'].agg(['mean','count']).sort_values(by='count')

energy_descrip.columns = ["Promedio", "Conteo"]

energy_descrip ## Data creado

"""# (f) ¿Qué canción tiene el “loudness” más bajo y cuál es la canción que tiene el “loudness” más alto?"""

loudness_alto = df[df['c_loudness'] == df['c_loudness'].max()]#nos da el valor maximo

loudness_alto[['c_loudness', 's_name', 's_artists']]

loudness_bajo = df[df['c_loudness'] == df['c_loudness'].min()]#Como hay varios con el más bajo muestra los 5

loudness_bajo[['c_loudness', 's_name', 's_artists']]

mas_bajo = df.nsmallest(1, 'c_loudness')#Aqui ya podemos solo tomar el primero
mas_bajo[['c_loudness', 's_name', 's_artists']]

"""# Extras
# Percentiles
"""

# Identificar variables continuas
variables_c = [col for col in df.columns if col.startswith('c_')]

# Calcular los 10 percentiles
percentiles = np.linspace(0, 100, 11)

# Percentiles para cada variable c
resultado = df[variables_c].quantile(percentiles/100)

percentiles

"""HOROSCOPOS"""

print('El prosesor es: Leo')
print('El ayudante es: Piscis')

"""#"""